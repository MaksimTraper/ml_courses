{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de7336",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1049a887",
   "metadata": {},
   "source": [
    "## Тэгирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from gigachat.models import Chat, Messages, MessagesRole, chat_completion\n",
    "\n",
    "from langchain_gigachat.chat_models import GigaChat\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "api_key  = os.getenv('GIGACHAT_API_KEY')\n",
    "\n",
    "model = GigaChat(credentials=api_key, verify_ssl_certs=False, temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb2ede9-b0b4-4c8c-b00f-9a9911f38614",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ae5481-4155-4831-a5dd-4c183b3b4990",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Пометьте фрагмент текста определенной информацией\"\"\"\n",
    "    sentiment: str = Field(description=\"тональность текста должна быть 'положительной', 'отрицательной' или 'нейтральной'\")\n",
    "    language: str = Field(description=\"язык текста (должен соответствовать коду ISO 639-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd656b2-62be-49d4-a277-b920c67203c1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maksim\\AppData\\Local\\Temp\\ipykernel_15020\\1725091243.py:1: LangChainDeprecationWarning: The function `_convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  convert_pydantic_to_openai_function(Tagging)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Пометьте фрагмент текста определенной информацией',\n",
       " 'parameters': {'properties': {'sentiment': {'description': \"тональность текста должна быть 'положительной', 'отрицательной' или 'нейтральной'\",\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'язык текста (должен соответствовать коду ISO 639-1)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8b15a7-450c-43d6-af44-ca63800a4619",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798ac5b3-7e47-4cfb-8173-63900cf1e7f6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d558031-18cf-4791-b061-8911ce314605",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Подумайте хорошенько, а затем пометьте текст в соответствии с инструкциями\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00607aff-a64e-42b7-8cf4-893e8393dd33",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0bc519-2b8e-40d0-88ec-fc5ef0291f16",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8688fdba-0996-446c-a77b-318094944998",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Tagging', 'arguments': {'language': 'ru', 'sentiment': 'положительная'}}, 'functions_state_id': 'e7b303c4-8bc2-47b8-a362-6c70b239cacc'}, response_metadata={'token_usage': {'prompt_tokens': 140, 'completion_tokens': 37, 'total_tokens': 177}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-0598fe1d-7f03-4ea1-8a38-eb793faecf10-0', tool_calls=[{'name': 'Tagging', 'args': {'language': 'ru', 'sentiment': 'положительная'}, 'id': '6f20e66f-086d-477b-b07a-930de6b4f141', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"Я люблю LangChain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7df9aac5-7194-4a12-bda7-e7e83e705929",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Tagging', 'arguments': {'language': 'it', 'sentiment': 'negative'}}, 'functions_state_id': '4fc070f4-14d8-455a-8d93-420f08ff96d7'}, response_metadata={'token_usage': {'prompt_tokens': 144, 'completion_tokens': 36, 'total_tokens': 180}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-d1197622-b6f6-4c1d-97f1-5f40444dbac6-0', tool_calls=[{'name': 'Tagging', 'args': {'language': 'it', 'sentiment': 'negative'}, 'id': '3e970ae9-b618-404c-b074-d2ae7959df46', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#я не люблю эту еду\n",
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0749e408-3878-4ddd-ad33-8d5b8418a3f2",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OutputFunctionsParser' from 'langchain.output_parsers.openai_functions' (c:\\Users\\Maksim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain\\output_parsers\\openai_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonOutputFunctionsParser, OutputFunctionsParser\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OutputFunctionsParser' from 'langchain.output_parsers.openai_functions' (c:\\Users\\Maksim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langchain\\output_parsers\\openai_functions.py)"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser, OutputFunctionsParser\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc45243e-7225-427d-b679-d737ebaec780",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "#tagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n",
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba84e64-518c-40e1-a7c9-d174314bc3fb",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Tagging', 'arguments': {'language': 'it', 'sentiment': 'negative'}}, 'functions_state_id': '8b2aeaf2-eba2-4cf5-bcfd-b40c690fb13b'}, response_metadata={'token_usage': {'prompt_tokens': 144, 'completion_tokens': 36, 'total_tokens': 180}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-628de4bc-9c35-4836-94e2-3f88802c6d9c-0', tool_calls=[{'name': 'Tagging', 'args': {'language': 'it', 'sentiment': 'negative'}, 'id': '3797aa1c-6de5-4364-8f61-03684ac5c8be', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0547cf",
   "metadata": {},
   "source": [
    "В дву последних ячейках предлагалось парсить аргументы от функции с помощью метода .JsonOutputFunctionsParser, но т.к. GigaChat возвращает сразу dict, парсинг не требуется (он и крашится), но нужно обращаться к аргументам вручную"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e417b4-9306-413f-865f-e13dbd2d0196",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97338dce-a61a-4f8b-912c-6108dcb86183",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"Имя человека\")\n",
    "    age: Optional[int] = Field(description=\"Возраст человека\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f558fb45-f3a5-47be-8778-dddec2d00ba1",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"Список информации о людях\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5eeb6028-0ade-46f6-a899-ca10f185bb24",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': 'Information to extract.',\n",
       " 'parameters': {'properties': {'people': {'description': 'Список информации о людях',\n",
       "    'items': {'description': 'Information about a person.',\n",
       "     'properties': {'name': {'description': 'Имя человека', 'type': 'string'},\n",
       "      'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "       'description': \"person's age\"}},\n",
       "     'required': ['name', 'age'],\n",
       "     'type': 'object'},\n",
       "    'type': 'array'}},\n",
       "  'required': ['people'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ac6fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_functions = [{\n",
    "    \"name\": \"Information\",\n",
    "    \"description\": \"List of people and their details\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"people\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"name\": {\"type\": \"string\", \"description\": \"Person's name\"},\n",
    "                        \"age\": {\"type\": \"integer\", \"description\": \"Person's age\"}\n",
    "                    },\n",
    "                    \"required\": [\"name\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"people\"]\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f16ce50e-bad7-4fbb-b9e2-0adae6fc55f2",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ed58069-3f7c-433e-93ed-5660d21435c9",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Information', 'arguments': {'people': [{'age': 30, 'name': 'Джо'}, {'name': 'Марта'}]}}, 'functions_state_id': '1e6bbd44-d7bd-447f-8298-39c5864f7e1d'}, response_metadata={'token_usage': {'prompt_tokens': 106, 'completion_tokens': 67, 'total_tokens': 173}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-1095a593-3fe1-4371-94c6-067e3f2c3b8e-0', tool_calls=[{'name': 'Information', 'args': {'people': [{'age': 30, 'name': 'Джо'}, {'name': 'Марта'}]}, 'id': 'b53c5734-f4e3-4978-b214-dd62f3ea13d2', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(\"Джо 30 лет, его мама - Марта\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79312d",
   "metadata": {},
   "source": [
    "Метод convert_pydantic_to_openai_function неправильно сформировал JSON (по крайней мере, GigaChat \"не понимает\" генерируемую структуру) для класса Pydantic со списком также класса Pydantic. Так что, видимо, такие функции нужно писать вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "172df097-250a-4813-b76d-21436c13056d",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Извлеките соответствующую информацию, если она не указана явно, не пытайтесь угадать. Извлеките частичную информацию\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfec48d7-25a2-46d7-a7a2-33284b577dd3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f19622af-4b01-4145-ae5a-af15b551a182",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Information', 'arguments': {'people': [{'age': 30, 'name': 'Джо'}, {'name': 'Марта'}]}}, 'functions_state_id': 'd9eefc4f-cd3c-47b8-a8ed-3317aebee73e'}, response_metadata={'token_usage': {'prompt_tokens': 138, 'completion_tokens': 67, 'total_tokens': 205}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-968b1742-0e43-4e83-8d50-b913fff52dd3-0', tool_calls=[{'name': 'Information', 'args': {'people': [{'age': 30, 'name': 'Джо'}, {'name': 'Марта'}]}, 'id': '0664f46b-74db-42f4-9961-3e74ad084ffc', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Джо 30 лет, его мама - Марта\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8db4b39-c28b-4c0e-8b9a-55ceb8ba817e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae23e56",
   "metadata": {},
   "source": [
    "Метод .JsonKeyOutputFunctionsParser, по идее, должен выделить параметры по ключу, но в данном случае это вновь не работает. Всё по тем же причинам, что и ранее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2901d3ac-4dfc-4fb9-afd3-ab056489d3ae",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "#extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8524f3-a663-4007-ad59-52dfe00343e9",
   "metadata": {},
   "source": [
    "## Doing it for real\n",
    "\n",
    "Мы можем применить теги к большому объему текста.\n",
    "\n",
    "Например, давайте загрузим эту запись в блоге и извлекем информацию о тегах из подмножества текста.\n",
    "\n",
    "<span style='color:gray'>\n",
    "We can apply tagging to a larger body of text.\n",
    "\n",
    "For example, let's load this blog post and extract tag information from a sub-set of the text.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc7c4a8c-d4c8-4400-b1d3-5c7c0c25786e",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dbd2e910-e0e0-447a-8118-6fe792f04e15",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "doc = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5e39f78-ff18-4016-a751-7d0e4c82bb36",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "page_content = doc.page_content[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb8d98ee-e9b2-4ce8-982a-c06dc006da76",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LLM Powered Autonomous Agents | Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "emojisearch.app\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "\n",
      "Agent System Overview\n",
      "\n",
      "Component One: Planning\n",
      "\n",
      "Task Decomposition\n",
      "\n",
      "Self-Reflection\n",
      "\n",
      "\n",
      "Component Two: Memory\n",
      "\n",
      "Types of Memory\n",
      "\n",
      "Maximum Inner Product Search (MIPS)\n",
      "\n",
      "\n",
      "Component Three: Tool Use\n",
      "\n",
      "Case Studies\n",
      "\n",
      "Scientific Discovery Agent\n",
      "\n",
      "Generative Agents Simulation\n",
      "\n",
      "Proof-of-Concept Examples\n",
      "\n",
      "\n",
      "Challenges\n",
      "\n",
      "Citation\n",
      "\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful gene\n"
     ]
    }
   ],
   "source": [
    "print(page_content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9db0d107-5284-4253-b769-dfedb97ce95d",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Предоставьте краткое изложение содержания.\")\n",
    "    language: str = Field(description=\"Укажите язык, на котором написан контент.\")\n",
    "    keywords: str = Field(description=\"Укажите ключевые слова, относящиеся к контенту.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6bfe7fe6-a86d-416c-a7f2-373dc70fcba5",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "518f2337-a8eb-4eff-b764-b70e48545d19",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "resp = tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c8787f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Overview',\n",
       " 'arguments': {'keywords': \"LLM Powered Autonomous Agents, Lil'Log\",\n",
       "  'language': 'en-US',\n",
       "  'summary': 'Overview of a section of text.'}}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.additional_kwargs['function_call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5be5d604-3d95-476a-afe4-b46b021534fc",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Информация об упомянутых документах.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Информация для извлечения\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e9db5aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Info',\n",
       " 'description': 'Информация для извлечения',\n",
       " 'parameters': {'properties': {'papers': {'items': {'description': 'Информация об упомянутых документах.',\n",
       "     'properties': {'title': {'type': 'string'},\n",
       "      'author': {'anyOf': [{'type': 'string'}, {'type': 'null'}]}},\n",
       "     'required': ['title', 'author'],\n",
       "     'type': 'object'},\n",
       "    'type': 'array'}},\n",
       "  'required': ['papers'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bccf74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_extraction_function = [{\n",
    "    \"name\": \"Info\",\n",
    "    \"description\": \"Список упомянутых документов\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"papers\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"title\": {\"type\": \"string\"},\n",
    "                        \"author\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"title\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"papers\"]\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "95045b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GigaChat(credentials=api_key, verify_ssl_certs=False, temperature = 0,\n",
    "#                 model=\"GigaChat-Max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8e56ca98-d05d-4199-a6ec-fe485b630da6",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_function, \n",
    "    function_call={\"name\":\"Info\"}\n",
    ")\n",
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f082b7a0-b7ea-488a-923c-aba8e4b185a0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Info', 'arguments': {'papers': []}}, 'functions_state_id': '40389175-6394-4014-b177-1aa3db5e8520'}, response_metadata={'token_usage': {'prompt_tokens': 2796, 'completion_tokens': 20, 'total_tokens': 2816}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-694a27fa-8f12-4591-bc38-e38ac929fddf-0', tool_calls=[{'name': 'Info', 'args': {'papers': []}, 'id': '2d688284-8426-48ad-a974-22dcc6e0d57d', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26265de",
   "metadata": {},
   "source": [
    "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Info', 'arguments': {'papers': [{'author': 'Wei et al. 2022', 'title': 'Chain of thought (CoT)'}, {'author': 'Yao et al. 2023', 'title': 'Tree of Thoughts'}, {'author': 'Liu et al. 2023', 'title': 'LLM+P'}, {'author': 'Yao et al. 2023', 'title': 'ReAct'}, {'author': 'Shinn & Labash 2023', 'title': 'Reflexion'}, {'author': 'Liu et al. 2023', 'title': 'Chain of Hindsight (CoH)'}, {'author': 'Laskin et al. 2023', 'title': 'Algorithm Distillation (AD)'}]}}, 'functions_state_id': '5cfb229e-f7b5-457d-94b2-c32a89022574'}, response_metadata={'token_usage': {'prompt_tokens': 2349, 'completion_tokens': 266, 'total_tokens': 2615}, 'model_name': 'GigaChat-Max:1.0.26.20', 'finish_reason': 'function_call'}, id='run-aff0dfff-d8ba-45be-9ae9-5cd6d8ad0176-0', tool_calls=[{'name': 'Info', 'args': {'papers': [{'author': 'Wei et al. 2022', 'title': 'Chain of thought (CoT)'}, {'author': 'Yao et al. 2023', 'title': 'Tree of Thoughts'}, {'author': 'Liu et al. 2023', 'title': 'LLM+P'}, {'author': 'Yao et al. 2023', 'title': 'ReAct'}, {'author': 'Shinn & Labash 2023', 'title': 'Reflexion'}, {'author': 'Liu et al. 2023', 'title': 'Chain of Hindsight (CoH)'}, {'author': 'Laskin et al. 2023', 'title': 'Algorithm Distillation (AD)'}]}, 'id': '10d1138f-a51d-4ad4-b7da-0b847618f6f1', 'type': 'tool_call'}])\n",
    "\n",
    "Т.е. большая модель - справилась. А Lite - нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a8dcce7-7032-49a8-893d-1659e2f51f03",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Вам будет передана статья. Извлеките из нее все статьи, которые упоминаются в этой статье, за которыми следует ее автор. \n",
    "\n",
    "Не извлекайте название самой статьи. Если статьи не упоминаются, это нормально - вам не нужно их извлекать! Просто верните пустой список.\n",
    "\n",
    "Не придумывайте и не домысливайте какую-либо дополнительную информацию. Извлекайте только то, что точно содержится в тексте.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5f4c8cc-d9a4-4556-a89e-94ec981c6f5e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b63e00b6-0f06-4e74-948e-04805e66f40c",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Info', 'arguments': {'Paper': [{'author': 'Lilian Weng', 'title': 'LLM Powered Autonomous Agents'}]}}, 'functions_state_id': 'cef56e44-ee19-4a20-892f-c6930d6ac6fa'}, response_metadata={'token_usage': {'prompt_tokens': 2797, 'completion_tokens': 59, 'total_tokens': 2856}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-c6174749-6be8-4123-adeb-64492ece142b-0', tool_calls=[{'name': 'Info', 'args': {'Paper': [{'author': 'Lilian Weng', 'title': 'LLM Powered Autonomous Agents'}]}, 'id': '29b5ef44-3b9a-4027-bc12-31310249a7d8', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "365bfa5b-f0d2-4a19-8db1-1b4a0f51703d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Info', 'arguments': {}}, 'functions_state_id': 'bf50ec6e-2ba5-4f31-8926-0009fe3d7183'}, response_metadata={'token_usage': {'prompt_tokens': 176, 'completion_tokens': 11, 'total_tokens': 187}, 'model_name': 'GigaChat:1.0.26.20', 'finish_reason': 'function_call'}, id='run-10e78dfd-ac30-440d-a5e7-34cdf051ed03-0', tool_calls=[{'name': 'Info', 'args': {}, 'id': '56aad9ed-6424-40ec-a5b6-0e5324f54e2e', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a3e18b5-0692-49dc-b589-5d4ae5a43fdd",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a851b07c-0f73-4cf1-801f-9832190db93a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "splits = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbd6fd3c-8fca-4f16-a256-a66577b48eb1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f1309bf-16a5-43ef-aa8e-427cf5120938",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5af35566-8f5f-4e02-86d2-c1a97ca4e573",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "67bded5d-de85-488c-bd3f-d83acbcfea33",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04233d0a-fe44-45ed-9145-af3caaa86863",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa8c2f1e-f3ac-4d9c-8ded-541778a32ef9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'hi'}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "44c9bed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.'}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.invoke(splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3f7d0255-4b58-42c9-a747-44768a866633",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "chain = prep | extraction_chain.map() | flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0dfa1f67-7246-4f4f-8967-4d7266df7b7a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('content', ''),\n",
       " ('additional_kwargs',\n",
       "  {'function_call': {'name': 'Info', 'arguments': {}},\n",
       "   'functions_state_id': '93f6a69c-c625-4a3b-b0ea-bf72b22569ac'}),\n",
       " ('response_metadata',\n",
       "  {'token_usage': {'prompt_tokens': 231,\n",
       "    'completion_tokens': 11,\n",
       "    'total_tokens': 242},\n",
       "   'model_name': 'GigaChat:1.0.26.20',\n",
       "   'finish_reason': 'function_call'}),\n",
       " ('type', 'ai'),\n",
       " ('name', None),\n",
       " ('id', 'run-669ac8de-7e7d-4e91-9ff3-bed0a0f0b27d-0'),\n",
       " ('example', False),\n",
       " ('tool_calls',\n",
       "  [{'name': 'Info',\n",
       "    'args': {},\n",
       "    'id': 'd73e0df3-732c-4530-bc7f-7d025e157d1a',\n",
       "    'type': 'tool_call'}]),\n",
       " ('invalid_tool_calls', []),\n",
       " ('usage_metadata', None)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd3b07",
   "metadata": {},
   "source": [
    "Хотелось бы верить, что более мощная модель справится с этим пайплайном, но GigaChat-Lite не справился :(\n",
    "+ ограничение на кол-во запросов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
